{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Practico 1\n",
    "\n",
    "Integrantes:\n",
    "* Mario Ferreyra\n",
    "* Emiliano Kokic\n",
    "* Francisco Crespo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Embedding, Lambda\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo usamos para la repetibilidad de resultados\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos y conversion de estos en vectores.\n",
    "def load_dataset():\n",
    "    dataset = load_files('./dataset/review_polarity/txt_sentoken', shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.25, random_state=42)\n",
    "\n",
    "    print('Training samples {}, test_samples {}'.format(\n",
    "        len(X_train), len(X_test)))\n",
    "\n",
    "    # TODO 1: Apply the Tfidf vectorizer to create input matrix\n",
    "    vectorizer1 = TfidfVectorizer(max_features = 10000)\n",
    "    vector1 = vectorizer1.fit_transform(X_train)\n",
    "    \n",
    "    vectorizer2 = TfidfVectorizer(max_features = 10000)\n",
    "    vector2 = vectorizer2.fit_transform(X_test)\n",
    "\n",
    "    return vector1, vector2, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples 1500, test_samples 500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9990</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7         8     9     ...   9990  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.023454   0.0  ...    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  ...    0.0   \n",
       "\n",
       "      9991  9992  9993  9994  9995  9996  9997  9998  9999  \n",
       "0  0.00000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  0.05202   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  0.00000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3  0.00000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  0.00000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las 10000 features más importantes\n",
    "data_example = pd.DataFrame(X_train.toarray())\n",
    "data_example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Convert the labels to categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_cat = le.fit_transform(y_train)\n",
    "y_test_cat = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que genera los modelos y que se usara en la grilla de validación cruzada.\n",
    "def build_model(nodes1 = 100, nodes2 = 200, lr = 0.001, \n",
    "                l2 = 0.01, input_shape = 10000, drop = 0.1):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes1,\n",
    "                    activation = 'relu',\n",
    "                    kernel_initializer = 'random_normal', \n",
    "                    input_shape = (input_shape, ),\n",
    "                    kernel_regularizer = regularizers.l2(l2)))\n",
    "    model.add(Dropout(drop))\n",
    "    \n",
    "    if(nodes2 != 0):\n",
    "        model.add(Dense(nodes2,\n",
    "                        activation = 'relu',\n",
    "                        kernel_initializer = 'random_normal',\n",
    "                        kernel_regularizer = regularizers.l2(l2)))\n",
    "        model.add(Dropout(drop))\n",
    "        model.add(Dense(2, activation = 'softmax'))\n",
    "        \n",
    "\n",
    "    opt = optimizers.Adam(lr = lr)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                  optimizer = opt, \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 10000\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Construcción del clasificador a partir de la función que crea el modelo\n",
    "model = KerasClassifier(build_fn = build_model, epochs = EPOCHS,\n",
    "                        batch_size = BATCH_SIZE, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l2': [0.0001, 0.001, 0.01], 'drop': [0.1, 0.2, 0.3]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de los valores de la grilla para la cross validation\n",
    "nodes1 = [32, 64, 128]\n",
    "nodes2 = [32, 64, 128, 256]\n",
    "lrs = [0.001, 0.002, 0.003]\n",
    "l2s = [0.0001, 0.001, 0.01]\n",
    "drops = [0.1, 0.2, 0.3]\n",
    "\n",
    "param_grid = dict(l2 = l2s, drop = drops)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] drop=0.1, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.1, l2=0.0001, total=   4.5s\n",
      "[CV] drop=0.1, l2=0.0001 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. drop=0.1, l2=0.0001, total=   4.2s\n",
      "[CV] drop=0.1, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.1, l2=0.0001, total=   4.7s\n",
      "[CV] drop=0.1, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.1, l2=0.001, total=   4.6s\n",
      "[CV] drop=0.1, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.1, l2=0.001, total=   4.5s\n",
      "[CV] drop=0.1, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.1, l2=0.001, total=   4.5s\n",
      "[CV] drop=0.1, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.1, l2=0.01, total=   4.7s\n",
      "[CV] drop=0.1, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.1, l2=0.01, total=   4.5s\n",
      "[CV] drop=0.1, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.1, l2=0.01, total=   4.7s\n",
      "[CV] drop=0.2, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.2, l2=0.0001, total=   4.9s\n",
      "[CV] drop=0.2, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.2, l2=0.0001, total=   4.8s\n",
      "[CV] drop=0.2, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.2, l2=0.0001, total=   4.7s\n",
      "[CV] drop=0.2, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.2, l2=0.001, total=   4.9s\n",
      "[CV] drop=0.2, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.2, l2=0.001, total=   5.0s\n",
      "[CV] drop=0.2, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.2, l2=0.001, total=   4.9s\n",
      "[CV] drop=0.2, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.2, l2=0.01, total=   5.1s\n",
      "[CV] drop=0.2, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.2, l2=0.01, total=   5.3s\n",
      "[CV] drop=0.2, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.2, l2=0.01, total=   5.2s\n",
      "[CV] drop=0.3, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.3, l2=0.0001, total=   5.3s\n",
      "[CV] drop=0.3, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.3, l2=0.0001, total=   5.1s\n",
      "[CV] drop=0.3, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.3, l2=0.0001, total=   5.2s\n",
      "[CV] drop=0.3, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.3, l2=0.001, total=   5.7s\n",
      "[CV] drop=0.3, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.3, l2=0.001, total=   5.5s\n",
      "[CV] drop=0.3, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.3, l2=0.001, total=   5.5s\n",
      "[CV] drop=0.3, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.3, l2=0.01, total=   5.6s\n",
      "[CV] drop=0.3, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.3, l2=0.01, total=   5.7s\n",
      "[CV] drop=0.3, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.3, l2=0.01, total=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                    cv = 3, n_jobs = 1, refit = True, verbose = 2)\n",
    "grid_result = grid.fit(X_train, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Precisión: 0.854667 con {'drop': 0.3, 'l2': 0.0001}\n",
      "0.848667 (0.006600) con: {'drop': 0.1, 'l2': 0.0001}\n",
      "0.841333 (0.011813) con: {'drop': 0.1, 'l2': 0.001}\n",
      "0.837333 (0.027047) con: {'drop': 0.1, 'l2': 0.01}\n",
      "0.852667 (0.006799) con: {'drop': 0.2, 'l2': 0.0001}\n",
      "0.838000 (0.013367) con: {'drop': 0.2, 'l2': 0.001}\n",
      "0.835333 (0.019137) con: {'drop': 0.2, 'l2': 0.01}\n",
      "0.854667 (0.009843) con: {'drop': 0.3, 'l2': 0.0001}\n",
      "0.849333 (0.012472) con: {'drop': 0.3, 'l2': 0.001}\n",
      "0.832667 (0.022291) con: {'drop': 0.3, 'l2': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Mostrar mejor resultado\n",
    "print(\"Mejores Precisión: %f con %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) con: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 100)               1000100   \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 1,020,702\n",
      "Trainable params: 1,020,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = build_model(l2 = 0.0001, drop = 0.3)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9021 - acc: 0.5373\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.7454 - acc: 0.8347\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.4003 - acc: 0.9233\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.1923 - acc: 0.9867\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.1382 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.1222 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 0s 236us/step - loss: 0.1003 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 0s 240us/step - loss: 0.0919 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.0841 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.0770 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 0s 253us/step - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 0s 241us/step - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 0.0395 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "history = final_model.fit(x = X_train, y = y_train_cat, batch_size = BATCH_SIZE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 201us/step\n",
      "Accuracy en test: 0.4780000002384186\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy en test:', final_model.evaluate(X_test, y_test_cat)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente estamos frente a un caso de overfitting.\n",
    "\n",
    "Probemos aumentar el parámetro de regularización asi como también el porcentaje de Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 100)               1000100   \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 1,020,702\n",
      "Trainable params: 1,020,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = build_model(l2 = 0.01, drop = 0.5)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 18.7793 - acc: 0.5073\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 0s 237us/step - loss: 8.7382 - acc: 0.5480\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 4.2862 - acc: 0.5567\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 2.3298 - acc: 0.6007\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 1.4513 - acc: 0.6220\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 0s 245us/step - loss: 1.0469 - acc: 0.6780\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.8486 - acc: 0.7667\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.7267 - acc: 0.8280\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.6301 - acc: 0.9120\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 0s 247us/step - loss: 0.5739 - acc: 0.9360\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.5332 - acc: 0.9573\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.4946 - acc: 0.9727\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 0s 246us/step - loss: 0.4720 - acc: 0.9713\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 0s 238us/step - loss: 0.4628 - acc: 0.9707\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.4449 - acc: 0.9747\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 0s 251us/step - loss: 0.4382 - acc: 0.9760\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 0s 244us/step - loss: 0.4220 - acc: 0.9807\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.4143 - acc: 0.9800\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 0s 249us/step - loss: 0.4019 - acc: 0.9807\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 0s 242us/step - loss: 0.4012 - acc: 0.9713\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "history = final_model.fit(x = X_train, y = y_train_cat, batch_size = BATCH_SIZE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step\n",
      "Accuracy en test: 0.5160000004768371\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy en test:', final_model.evaluate(X_test, y_test_cat)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aumentar el parámetro de regularización y el porcentaje de dropouts el modelo generaliza un poco más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_input(instances, mapping):\n",
    "    \"\"\"\n",
    "    Replaces the words in instances with their index in mapping.\n",
    "\n",
    "    Args:\n",
    "        instances: a list of text instances.\n",
    "        mapping: an dictionary from words to indices.\n",
    "\n",
    "    Returns:\n",
    "        A matrix with shape (n_instances, max_text_length).\n",
    "    \"\"\"\n",
    "    word_indices = []\n",
    "    for instance in instances:\n",
    "        word_indices.append([mapping[word.decode('utf-8')]\n",
    "                             for word in instance.split()])\n",
    "    # Check consistency\n",
    "    assert len(instances[0].split()) == len(word_indices[0])\n",
    "\n",
    "    # Pad the sequences to obtain a matrix instead of a list of lists.\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    return pad_sequences(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./filteredFastText', 'rb') as model_file:\n",
    "    filtered_fasttext = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset2():\n",
    "    dataset = load_files('./dataset/review_polarity/txt_sentoken',\n",
    "                         shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.data,\n",
    "                                                        dataset.target,\n",
    "                                                        test_size=0.1, # antes estaba en 0.25\n",
    "                                                        random_state=42)\n",
    "    print('Training samples {}, test_samples {}'\n",
    "          .format(len(X_train), len(X_test)))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples 1800, test_samples 200\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test_original = load_dataset2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = transform_input(X_train, filtered_fasttext.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que genera los modelos y que se usara en la grilla de validación cruzada.\n",
    "def build_model2(nodes1 = 100, nodes2 = 200, lr = 0.001, \n",
    "                l2 = 0.01, drop = 0.1):\n",
    "    \n",
    "    model = Sequential()  \n",
    "    model.add(\n",
    "        Embedding(\n",
    "            filtered_fasttext.wv.shape[0],  # Vocabulary size\n",
    "            filtered_fasttext.wv.shape[1],  # Embedding size\n",
    "            weights=[filtered_fasttext.wv],  # Word vectors\n",
    "            trainable=False  # This indicates the word vectors must not be\n",
    "        )                    # changed during training.\n",
    "    )\n",
    "    model.add(\n",
    "        Lambda(lambda xin: K.mean(xin, axis=1), name='embedding_average')\n",
    "    #     Lambda(lambda xin: K.concatenate([K.min(xin, axis=1), K.max(xin, axis=1)]),\n",
    "    #            name='embedding_min_max')\n",
    "    )      \n",
    "    model.add(Dense(nodes1,\n",
    "                    activation = 'relu',\n",
    "                    kernel_initializer = 'random_normal', \n",
    "                    kernel_regularizer = regularizers.l2(l2)\n",
    "             )\n",
    "    )      \n",
    "    model.add(Dropout(drop))   \n",
    "    if(nodes2 != 0):\n",
    "        model.add(Dense(nodes2,\n",
    "                        activation = 'relu',\n",
    "                        kernel_initializer = 'random_normal',\n",
    "                        kernel_regularizer = regularizers.l2(l2)))\n",
    "        model.add(Dropout(drop))\n",
    "        model.add(Dense(1, activation = 'sigmoid'))  \n",
    "\n",
    "    opt = optimizers.Adadelta(lr = lr)\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                  optimizer = opt, \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "# Construcción del clasificador a partir de la función que crea el modelo\n",
    "model = KerasClassifier(build_fn = build_model2, epochs = EPOCHS,\n",
    "                        batch_size = BATCH_SIZE, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l2': [0.0001, 0.001, 0.01], 'drop': [0.1, 0.2, 0.3]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de los valores de la grilla para la cross validation\n",
    "nodes1 = [32, 64, 128]\n",
    "nodes2 = [32, 64, 128, 256]\n",
    "lrs = [0.001, 0.002, 0.003]\n",
    "l2s = [0.0001, 0.001, 0.01]\n",
    "drops = [0.1, 0.2, 0.3]\n",
    "\n",
    "param_grid = dict(l2 = l2s, drop = drops)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] drop=0.1, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.1, l2=0.0001, total=   6.9s\n",
      "[CV] drop=0.1, l2=0.0001 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. drop=0.1, l2=0.0001, total=   8.4s\n",
      "[CV] drop=0.1, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.1, l2=0.0001, total=  10.3s\n",
      "[CV] drop=0.1, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.1, l2=0.001, total=  12.6s\n",
      "[CV] drop=0.1, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.1, l2=0.001, total=  13.3s\n",
      "[CV] drop=0.1, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.1, l2=0.001, total=  13.3s\n",
      "[CV] drop=0.1, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.1, l2=0.01, total=  13.2s\n",
      "[CV] drop=0.1, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.1, l2=0.01, total=  13.0s\n",
      "[CV] drop=0.1, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.1, l2=0.01, total=  13.1s\n",
      "[CV] drop=0.2, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.2, l2=0.0001, total=  13.3s\n",
      "[CV] drop=0.2, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.2, l2=0.0001, total=  13.9s\n",
      "[CV] drop=0.2, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.2, l2=0.0001, total=  13.8s\n",
      "[CV] drop=0.2, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.2, l2=0.001, total=  13.7s\n",
      "[CV] drop=0.2, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.2, l2=0.001, total=  13.6s\n",
      "[CV] drop=0.2, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.2, l2=0.001, total=  13.7s\n",
      "[CV] drop=0.2, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.2, l2=0.01, total=  13.7s\n",
      "[CV] drop=0.2, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.2, l2=0.01, total=  14.3s\n",
      "[CV] drop=0.2, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.2, l2=0.01, total=  14.0s\n",
      "[CV] drop=0.3, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.3, l2=0.0001, total=  14.2s\n",
      "[CV] drop=0.3, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.3, l2=0.0001, total=  14.1s\n",
      "[CV] drop=0.3, l2=0.0001 .............................................\n",
      "[CV] .............................. drop=0.3, l2=0.0001, total=  14.2s\n",
      "[CV] drop=0.3, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.3, l2=0.001, total=  14.6s\n",
      "[CV] drop=0.3, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.3, l2=0.001, total=  14.6s\n",
      "[CV] drop=0.3, l2=0.001 ..............................................\n",
      "[CV] ............................... drop=0.3, l2=0.001, total=  14.7s\n",
      "[CV] drop=0.3, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.3, l2=0.01, total=  15.0s\n",
      "[CV] drop=0.3, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.3, l2=0.01, total=  15.2s\n",
      "[CV] drop=0.3, l2=0.01 ...............................................\n",
      "[CV] ................................ drop=0.3, l2=0.01, total=  14.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  6.3min finished\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                    cv = 3, n_jobs = 1, refit = True, verbose = 2)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Precisión: 0.513889 con {'drop': 0.3, 'l2': 0.0001}\n",
      "0.481667 (0.008498) con: {'drop': 0.1, 'l2': 0.0001}\n",
      "0.486111 (0.014678) con: {'drop': 0.1, 'l2': 0.001}\n",
      "0.481667 (0.008498) con: {'drop': 0.1, 'l2': 0.01}\n",
      "0.485556 (0.005666) con: {'drop': 0.2, 'l2': 0.0001}\n",
      "0.483333 (0.007201) con: {'drop': 0.2, 'l2': 0.001}\n",
      "0.503889 (0.019830) con: {'drop': 0.2, 'l2': 0.01}\n",
      "0.513889 (0.014678) con: {'drop': 0.3, 'l2': 0.0001}\n",
      "0.462222 (0.033948) con: {'drop': 0.3, 'l2': 0.001}\n",
      "0.498333 (0.018708) con: {'drop': 0.3, 'l2': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Mostrar mejor resultado\n",
    "print(\"Mejores Precisión: %f con %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) con: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, None, 300)         15276000  \n",
      "_________________________________________________________________\n",
      "embedding_average (Lambda)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 15,326,501\n",
      "Trainable params: 50,501\n",
      "Non-trainable params: 15,276,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = build_model2(l2 = 0.0001, drop = 0.3)\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1800/1800 [==============================] - 2s 1ms/step - loss: 0.7076 - acc: 0.5011\n",
      "Epoch 2/20\n",
      "1800/1800 [==============================] - 1s 600us/step - loss: 0.7057 - acc: 0.5078\n",
      "Epoch 3/20\n",
      "1800/1800 [==============================] - 1s 598us/step - loss: 0.7067 - acc: 0.4944\n",
      "Epoch 4/20\n",
      "1800/1800 [==============================] - 1s 598us/step - loss: 0.7071 - acc: 0.4922\n",
      "Epoch 5/20\n",
      "1800/1800 [==============================] - 1s 603us/step - loss: 0.7070 - acc: 0.5022\n",
      "Epoch 6/20\n",
      "1800/1800 [==============================] - 1s 603us/step - loss: 0.7063 - acc: 0.5061\n",
      "Epoch 7/20\n",
      "1800/1800 [==============================] - 1s 597us/step - loss: 0.7058 - acc: 0.5011\n",
      "Epoch 8/20\n",
      "1800/1800 [==============================] - 1s 601us/step - loss: 0.7074 - acc: 0.4911\n",
      "Epoch 9/20\n",
      "1800/1800 [==============================] - 1s 594us/step - loss: 0.7061 - acc: 0.5072\n",
      "Epoch 10/20\n",
      "1800/1800 [==============================] - 1s 594us/step - loss: 0.7060 - acc: 0.5017\n",
      "Epoch 11/20\n",
      "1800/1800 [==============================] - 1s 596us/step - loss: 0.7050 - acc: 0.5133\n",
      "Epoch 12/20\n",
      "1800/1800 [==============================] - 1s 596us/step - loss: 0.7082 - acc: 0.4856\n",
      "Epoch 13/20\n",
      "1800/1800 [==============================] - 1s 606us/step - loss: 0.7050 - acc: 0.5200\n",
      "Epoch 14/20\n",
      "1800/1800 [==============================] - 1s 613us/step - loss: 0.7063 - acc: 0.5133\n",
      "Epoch 15/20\n",
      "1800/1800 [==============================] - 1s 602us/step - loss: 0.7062 - acc: 0.5000\n",
      "Epoch 16/20\n",
      "1800/1800 [==============================] - 1s 594us/step - loss: 0.7072 - acc: 0.5072\n",
      "Epoch 17/20\n",
      "1800/1800 [==============================] - 1s 602us/step - loss: 0.7051 - acc: 0.5267\n",
      "Epoch 18/20\n",
      "1800/1800 [==============================] - 1s 599us/step - loss: 0.7050 - acc: 0.5050\n",
      "Epoch 19/20\n",
      "1800/1800 [==============================] - 1s 600us/step - loss: 0.7041 - acc: 0.5183\n",
      "Epoch 20/20\n",
      "1800/1800 [==============================] - 1s 600us/step - loss: 0.7057 - acc: 0.5039\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "history = final_model.fit(x = X_train, y = y_train, batch_size = BATCH_SIZE, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = transform_input(X_test, filtered_fasttext.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 540us/step\n",
      "Accuracy en test: 0.495\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy en test:', final_model.evaluate(X_test, y_test_original)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
