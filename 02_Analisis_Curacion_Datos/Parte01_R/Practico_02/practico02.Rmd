---
title: "Analisis exploratorio y curacion de datos"
author: "Mario Ferreyra - Emiliano Kokic"
date: "19 de Mayo 2018"
---

--------------------------------------------------------------------------------

Practico 2
==========
Entregar un Rmd donde se:

- Elija un dataset clasificado de su preferencia y area (domain expertise), aplique un metodo de clustering y/o mixtura de Gaussianas en el mismo.

- Investigue los resultados en el meta parametro $K$ numero de cumulos e investigue posibles procesos de seleccion del mismo.

- Elabore un resumen, y selecione un mejor valor segun el/los criterios aplicados, discuta el significado de los cumulos encontrados. 

- Comente la influencia de la normalizacion de los datos en los resultados del clustering.

--------------------------------------------------------------------------------
Haberman's Survival Data

Informacion relevante:
   El conjunto de datos contiene casos de un estudio que se realizo entre
   1958 y 1970 en el Hospital Billings de la Universidad de Chicago en
   la supervivencia de los pacientes que se habian sometido a cirugia de
   cancer de mama.
   
Numero de Instancias: 306

Numero de Atributos: 4 (incluyendo el atributo de clase)

Informacion sobre los atributos:
   1. Age of patient at time of operation (numerical)
   2. Patient's year of operation (year - 1900, numerical)
   3. Number of positive axillary nodes detected (numerical)
   4. Survival status (class attribute)
         1 = the patient survived 5 years or longer
         2 = the patient died within 5 year

Missing Attribute Values: None
--------------------------------------------------------------------------------

```{r echo=TRUE}
haberman_data <- read.csv("haberman.data", header=FALSE)
str(haberman_data)
d <- dim(haberman_data)
print(paste0("Filas: ", d[1], " Columnas: ", d[2]))
```

```{r echo=TRUE}
library("dplyr")
haberman_data <- rename(haberman_data,
                        patient_Age=V1,
                        operation_Year=V2,
                        positive_axillary_Nodes=V3,
                        survival_Status=V4)
head(haberman_data, 5)
```

```{r echo=TRUE}
# Shuffle rows
haberman_data <- haberman_data[sample(nrow(haberman_data)),]
head(haberman_data, 10)
```


```{r echo=TRUE}
# Min-Max normalization
normalizeMinMax <- function(x) {
  return ((x-min(x))/(max(x)-min(x)))
}
haberman_data_MinMax <- as.data.frame(lapply(haberman_data[1:3], normalizeMinMax))

# Z-Score normalization
haberman_data_ZScore <- as.data.frame(lapply(haberman_data[1:3], scale))
summary(haberman_data_ZScore)
```

```{r}
library(scatterplot3d)
attach(haberman_data_ZScore)
scatterplot3d(patient_Age, operation_Year, positive_axillary_Nodes)
```


```{r echo=TRUE}
# Plot our dataset.
plot(haberman_data[,1:3], col = haberman_data$survival_Status, pch = 18, main = "Fisher's Haberman Dataset")
```


```{r}
# 70% to train
data_train_1 <- haberman_data_MinMax[1:214, ]
data_train_2 <- haberman_data_ZScore[1:214, ]
# 30% to test
data_test_1 <- haberman_data_MinMax[215:306, ]
data_test_2 <- haberman_data_ZScore[215:306, ]
```


```{r}
data_train_labels <- haberman_data[1:214, 4]
data_test_labels  <- haberman_data[215:306, 4]
```

```{r}
library(class)
# Apply KNN with parameter k in [1,20] and two diferent normalizations
predictions1 <- matrix(nrow=0, ncol = 92)
predictions2 <- matrix(nrow=0, ncol = 92)

# Each row of the matrix will be a prediction with diferent K
for (i in seq(1,20)) {
  predictions1 <- rbind(predictions1, knn(train=data_train_1,
                                          test=data_test_1,
                                          cl=data_train_labels,
                                          k=i))
  predictions2 <- rbind(predictions2, knn(train=data_train_2,
                                          test=data_test_2,
                                          cl=data_train_labels,
                                          k=i))
}
```


```{r}
# Function to obtain the Accuracy
library(gmodels)
getAccuracy <- function(data_test_labels, data_test_pred) {
  
  # ENCONTRAR UNA FORMA PARA QUE EL CrossTable NO SE IMPRIMA!
  
  cross <- CrossTable(x=data_test_labels, y=data_test_pred,
                      prop.chisq = FALSE, prop.r=FALSE,
                      prop.c=FALSE, prop.t=FALSE)
  cross_df <- as.data.frame(cross)

  total_test <- sum(cross_df$t.Freq)

  # subcross_df <- subset(cross_df, cross_df$t.x == m$t.y)
  subcross_df <- subset(cross_df, cross_df$t.x == cross_df$t.y)
  success = sum(subcross_df$t.Freq)
  accuracy = success / total_test

  return(accuracy)
}
```


```{r}
# Print the best accuracy and K from predictions
getBestAcc_K <- function(predictions, k) {
  bestK <- 0
  bestAccuracy <- 0
  for (i in seq(1,k)) {
    acc = getAccuracy(data_test_labels = data_test_labels, data_test_pred = predictions[i,])
    if (acc > bestAccuracy) {
      bestAccuracy <- acc
      bestK <- i
    }
  }
  result <- list(bestAccuracy, bestK)

  return(result)
}
```


```{r}
# Best accuracy and K for Min-Max Normalization
acc_k_1 <- getBestAcc_K(predictions1, 20)
bestAcc_1 <- acc_k_1[1]
bestK_1 <- acc_k_1[2]

# Best accuracy and K for ZScore Normalization
acc_k_2 <- getBestAcc_K(predictions2, 20)
bestAcc_2 <- acc_k_2[1]
bestK_2 <- acc_k_2[2]

print("Using Min-Max Normalization")
print(paste0("The best accuracy is: ", bestAcc_1, " with K = ", bestK_1))
print("")
print("Using ZScore Normalization")
print(paste0("The best accuracy is: ", bestAcc_2, " with K = ", bestK_2))
```

Conclusiones
============

- Luego de haber normalizado los datos aplicando los metodos MinMax y ZScore determinamos que aplicando la normalizacion MinMax y posteriormente knn obtenemos mejores resultados.

- Para la seleccion del K se ejecuto knn modificando el valor de K en el rango 1:20 y obtener el que tuviese mejor accuracy.

- Otro aspecto a destacar es que en general hay un muy bajo porcentaje de falsos negativos (personas que sobrevivieron pero que se las catalogo como fallecida) pero sin embargo, muy alta proporcion de falsos positivos(personas que fallecieron pero se las catalogo como sobrevivientes).


